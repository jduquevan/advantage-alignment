{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributions as D\n",
    "\n",
    "class MixtureDistribution(D.Distribution):\n",
    "    def __init__(self, base_dist, uniform_low, uniform_high, mixture_weight):\n",
    "        super().__init__(validate_args=False)\n",
    "        self.base_dist = base_dist\n",
    "        self.uniform_dist = D.Uniform(uniform_low, uniform_high)\n",
    "        self.mixture_weight = mixture_weight\n",
    "        \n",
    "    def sample(self):\n",
    "        base_samples = self.base_dist.sample()\n",
    "        uniform_samples = self.uniform_dist.sample(sample_shape=base_samples.shape)\n",
    "\n",
    "        mixture_samples = torch.bernoulli(self.mixture_weight * torch.ones_like(base_samples)).bool()\n",
    "        print(uniform_samples)\n",
    "\n",
    "        samples = torch.where(mixture_samples, uniform_samples, base_samples)\n",
    "        return samples\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        base_log_prob = self.base_dist.log_prob(x)\n",
    "        uniform_log_prob = self.uniform_dist.log_prob(x)\n",
    "\n",
    "        base_weighted_log_prob = torch.log(1 - self.mixture_weight) + base_log_prob\n",
    "        uniform_weighted_log_prob = torch.log(self.mixture_weight) + uniform_log_prob\n",
    "        \n",
    "        print(base_weighted_log_prob.shape, \n",
    "              uniform_weighted_log_prob.shape,\n",
    "              torch.stack([base_weighted_log_prob, uniform_weighted_log_prob]).shape)\n",
    "\n",
    "        return torch.logsumexp(\n",
    "            torch.stack([base_weighted_log_prob, uniform_weighted_log_prob], axis=-1),\n",
    "            dim=-1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.distributions import SigmoidTransform\n",
    "\n",
    "base_prop_dist = D.normal.Normal(\n",
    "            loc=torch.zeros((4096, 3)),\n",
    "            scale=torch.exp(torch.ones((4096, 3))*-2.)\n",
    "        )\n",
    "\n",
    "prop_normal_sigmoid = D.TransformedDistribution(base_prop_dist, [SigmoidTransform()])\n",
    "\n",
    "mixture_dist = MixtureDistribution(\n",
    "    prop_normal_sigmoid,\n",
    "    torch.tensor(0.0),\n",
    "    torch.tensor(1.0),\n",
    "    torch.tensor(0.5)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6524d3c220d7d6bb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "samples = mixture_dist.sample()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65e5d5d6bde66dfd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "slice = samples[:, 2]\n",
    "# plot histogram between 0 and 1\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(slice.numpy(), bins=100, density=True)\n",
    "# force hist between 0 and 1\n",
    "plt.xlim(0, 1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a599c2ecb8e78381",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mixture_dist.log_prob(samples).shape\n",
    "plt.scatter(samples, mixture_dist.log_prob(samples), s=1.)\n",
    "plt.ylim(-5, 5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbb4e444d8dee5d9",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
