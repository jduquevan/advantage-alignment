seed: 1
batch_size: 512
wandb: 'online'
wandb_dir: /network/scratch/j/juan.duque/wandb/
use_transformer: False
sum_rewards: True
simultaneous: True
discrete: True
self_play: True
share_encoder: True

env:
  device: cuda

hydra:
  output_subdir: null
  run:
    dir: /network/scratch/j/juan.duque/hydra/

lg:
  _target_: src.algorithms.db.DB

# Architecture hyperparameters
network:
  _target_: src.networks.gru_network.GruIPD
  device: cuda

gru_model:
  _target_: src.models.models.GruModel
  in_size: 15
  device: cuda
  hidden_size: 64
  num_layers: 1

transformer_model:
  _target_: src.models.models.StableTransformer
  in_size: 15
  d_model: 64
  device: cuda
  dim_feedforward: 64
  num_layers: 1
  nhead: 4
  max_seq_len: 50
  dropout: 0.1

mlp_model:
  _target_: src.models.models.MLPModelDiscrete
  in_size: 64
  device: cuda
  hidden_size: 40

policy:
  _target_: src.agents.policies.CategoricalPolicy
  log_std_min: -10.0
  log_std_max: 2.0
  prop_max: 1 # item max quantity
  device: cuda

linear_model:
  _target_: src.models.models.LinearModel
  in_size: 64
  out_size: 1
  device: cuda

optimizer_actor:
  _target_: torch.optim.Adam
  lr: 1e-5

optimizer_critic:
  _target_: torch.optim.Adam
  lr: 1e-3

agent:
  _target_: src.agents.agents.AdvantageAlignmentAgent
  device: cuda

training:
  gamma: 0.96
  tau: 0.005
  max_traj_len: 50
  batch_size: 512 # Training batch size
  total_steps: 100000 # Number of optimization steps to train for
  eval_every: 100 # Number of optimization steps before evaluation
  proximal: True
  clip_range: 0.15
  entropy_beta: 0.07
  vanilla: True
  updates_per_batch: 1